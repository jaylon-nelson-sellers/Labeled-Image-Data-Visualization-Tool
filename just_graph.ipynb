{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotnine in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.14.5)\n",
      "Requirement already satisfied: matplotlib>=3.8.0 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotnine) (3.9.0)\n",
      "Requirement already satisfied: pandas>=2.2.0 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotnine) (2.2.2)\n",
      "Requirement already satisfied: mizani~=0.13.0 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotnine) (0.13.1)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotnine) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotnine) (1.13.1)\n",
      "Requirement already satisfied: statsmodels>=0.14.0 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotnine) (0.14.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.8.0->plotnine) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.8.0->plotnine) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.8.0->plotnine) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.8.0->plotnine) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.8.0->plotnine) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.8.0->plotnine) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.8.0->plotnine) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.8.0->plotnine) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mizani~=0.13.0->plotnine) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=2.2.0->plotnine) (2024.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from statsmodels>=0.14.0->plotnine) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jaylo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->plotnine) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\jaylo\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, KernelPCA, FastICA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import os\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Index([], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adjusting positions: 100%|██████████| 1000/1000 [00:00<00:00, 8620.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Results saved to 'data-1d.csv', 'data-2d.csv' and 'TSNE_clustering_images.png'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, KernelPCA, FastICA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import os\n",
    "import spacy \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from PIL import Image, ImageDraw\n",
    "import plotnine as gg\n",
    "from plotnine import *\n",
    "from PIL import Image, ImageDraw, ImageChops\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Circle\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from tqdm import tqdm \n",
    "\n",
    "def preprocess_data(text,data_name):\n",
    "    \n",
    "\n",
    "    # Function to lemmatize text using spaCy\n",
    "    def lemmatize_text(text):\n",
    "        doc = nlp(text)\n",
    "        return \" \".join([token.lemma_ for token in doc])\n",
    "        # Load spaCy model\n",
    "        #nlp = spacy.load(\"en_core_web_sm\")\n",
    "     # Load the data\n",
    "    data = pd.read_csv(data_name)\n",
    "    \n",
    "    \n",
    "    # Extract character names and remove from main data\n",
    "    ids = data.iloc[:, 0].tolist()\n",
    "    print(ids)\n",
    "    main_data = data.iloc[:, 2:]\n",
    "\n",
    "    # Identify numeric and text columns\n",
    "    numeric_columns = main_data.select_dtypes(include=[np.number]).columns\n",
    "    text_columns = main_data.select_dtypes(exclude=[np.number]).columns\n",
    "    print(text_columns)\n",
    "    # Preprocess numeric columns\n",
    "    #scaler = StandardScaler()\n",
    "    #imputer = SimpleImputer(strategy='mean')\n",
    "    #numeric_data = pd.DataFrame(scaler.fit_transform(imputer.fit_transform(main_data[numeric_columns])), \n",
    "    #                           columns=numeric_columns)\n",
    "   \n",
    "\n",
    "    # Preprocess text columns using TfidfVectorizer and spaCy lemmatization\n",
    "    if text:\n",
    "        tfidf = TfidfVectorizer()  # You can adjust max_features as needed\n",
    "        text_data = main_data[text_columns].fillna('')\n",
    "        text_data_combined = text_data.apply(lambda x: ' '.join(x), axis=1)\n",
    "        print(text_data_combined)\n",
    "        #lemmatized_text = text_data_combined.apply(lemmatize_text)\n",
    "        tfidf_matrix = tfidf.fit_transform(text_data_combined)\n",
    "        tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "        processed_data = pd.concat([tfidf_df], axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return [main_data,ids]\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "def crop_to_circle(image):\n",
    "    # Convert to RGBA if not already\n",
    "    image = image.convert('RGBA')\n",
    "    \n",
    "    # Create a circular mask\n",
    "    mask = Image.new('L', image.size, 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    draw.ellipse((0, 0) + image.size, fill=255)\n",
    "    \n",
    "    # Get the alpha channel from the original image\n",
    "    original_alpha = image.split()[3]\n",
    "    \n",
    "    # Combine the circular mask with the original alpha channel\n",
    "    new_alpha = ImageChops.multiply(mask, original_alpha)\n",
    "    \n",
    "    # Create a new image with the modified alpha channel\n",
    "    r, g, b, _ = image.split()\n",
    "    output = Image.merge('RGBA', (r, g, b, new_alpha))\n",
    "    \n",
    "    return output\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from tqdm import tqdm\n",
    "def apply_force_spacing(positions, names, min_distance=1.0, iterations=50, force_strength=0.1, normalize=True):\n",
    "    \"\"\"\n",
    "    Apply force-directed spacing to ensure elements aren't too close.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    positions : np.ndarray\n",
    "        Array of shape (n, d) containing the positions.\n",
    "    names : list\n",
    "        List of names (unused but kept for compatibility).\n",
    "    min_distance : float\n",
    "        Minimum allowed distance between elements.\n",
    "    iterations : int\n",
    "        Number of iterations for force adjustment.\n",
    "    force_strength : float\n",
    "        Strength of the repulsive force.\n",
    "    normalize : bool\n",
    "        Whether to normalize positions into [-1, 1] range before processing.\n",
    "    \"\"\"\n",
    "    # Normalize positions first\n",
    "    if normalize:\n",
    "        min_vals = positions.min(axis=0)\n",
    "        max_vals = positions.max(axis=0)\n",
    "        ranges = np.where(max_vals - min_vals == 0, 1, max_vals - min_vals)  # prevent div by zero\n",
    "        # Scale into [-1, 1]\n",
    "        positions = 2 * (positions - min_vals) / ranges - 1\n",
    "\n",
    "    for _ in tqdm(range(iterations), desc=\"Adjusting positions\"):\n",
    "        distances = squareform(pdist(positions))\n",
    "        \n",
    "        for i in range(len(positions)):\n",
    "            too_close = np.where(distances[i] < min_distance)[0]\n",
    "            too_close = too_close[too_close != i]\n",
    "            \n",
    "            if len(too_close) > 0:\n",
    "                for j in too_close:\n",
    "                    diff = positions[i] - positions[j]\n",
    "                    length = np.linalg.norm(diff)\n",
    "                    if length > 0:\n",
    "                        diff = diff / length\n",
    "                        force = force_strength * (min_distance - length)\n",
    "                        positions[i] += diff * force\n",
    "                        positions[j] -= diff * force\n",
    "    \n",
    "    return positions\n",
    "\n",
    "\n",
    "def get_column(list_of_lists, column_index):\n",
    "  \"\"\"\n",
    "  Returns a column from a list of lists.\n",
    "\n",
    "  Args:\n",
    "    list_of_lists: The list of lists.\n",
    "    column_index: The index of the column to get.\n",
    "\n",
    "  Returns:\n",
    "    A list containing the elements of the specified column.\n",
    "  \"\"\"\n",
    "  return [row[column_index] for row in list_of_lists]\n",
    "\n",
    "def decompose_data(processed_data, id_label_data):\n",
    "    image_size = .05\n",
    "    image_size_ratio = image_size*50000\n",
    "    def get_image(path, zoom=image_size):\n",
    "        img = plt.imread(path)\n",
    "        if isinstance(img, np.ndarray):\n",
    "            # Convert to PIL Image\n",
    "            img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "        img = crop_to_circle(img)\n",
    "        return OffsetImage(img, zoom=zoom)\n",
    "\n",
    "   \n",
    "    \n",
    "    ids = id_label_data\n",
    "\n",
    "  \n",
    "        # 2D decomposition\n",
    "    tsne2 = PCA(n_components=2)\n",
    "    processed_data= tsne2.fit_transform(processed_data)\n",
    "\n",
    "    \n",
    "    # Apply force-directed spacing with more reasonable parameters\n",
    "    spaced_positions = apply_force_spacing(\n",
    "        processed_data,\n",
    "        ids,\n",
    "        min_distance=0.35,  # Now works with normalized data\n",
    "        iterations=1000,\n",
    "        force_strength=0.01\n",
    "    )\n",
    "\n",
    "    # Clustering on the spaced positions\n",
    "    kmeans_2d = KMeans(n_clusters=5, random_state=42)\n",
    "    clusters_2d = kmeans_2d.fit_predict(spaced_positions)\n",
    "    \n",
    "\n",
    "\n",
    "    colors = [\n",
    "        '#BF0D3E', \n",
    "        '#1B4D89', \n",
    "        '#006B54',  \n",
    "        '#7B2CBF',  \n",
    "        '#CC5500',  \n",
    "        #'#116466', \n",
    "        #'#9B2226',  \n",
    "        #'#354F52',\n",
    "        #'#6B4423',  \n",
    "        #'#693C72' \n",
    "    ]\n",
    "    # Create the graph\n",
    "    plt.figure()\n",
    "    \n",
    "    \n",
    "    # Plot colored circles for each cluster\n",
    "    for cluster in range(5):  # Changed to 8 clusters\n",
    "        mask = clusters_2d == cluster\n",
    "        plt.scatter(spaced_positions[mask, 0], spaced_positions[mask, 1], \n",
    "                   color=colors[cluster], alpha=0.7, s=image_size_ratio)\n",
    "\n",
    "        # Add character images\n",
    "    for i, character in enumerate(ids):\n",
    "        try:\n",
    "            img_path = os.path.join('images', f\"{character}.png\")\n",
    "            ab = AnnotationBbox(get_image(img_path), \n",
    "                                (spaced_positions[i, 0], spaced_positions[i, 1]), \n",
    "                                frameon=False)\n",
    "            plt.gca().add_artist(ab)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image not found for {character}\")\n",
    "\n",
    "    # Adjust plot limits to be slightly beyond [-1,1]\n",
    "    x_min, x_max = spaced_positions[:, 0].min(), spaced_positions[:, 0].max()\n",
    "    y_min, y_max = spaced_positions[:, 1].min(), spaced_positions[:, 1].max()\n",
    "\n",
    "    margin = 0.3  # 10% extra space\n",
    "    plt.xlim(x_min - margin, x_max + margin)\n",
    "    plt.ylim(y_min - margin, y_max + margin)\n",
    "\n",
    "    plt.suptitle('')\n",
    "    plt.savefig('clustering_image.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    print(\"Processing complete. Results saved to 'data-1d.csv', 'data-2d.csv' and 'TSNE_clustering_images.png'.\")\n",
    "\n",
    "df,chars = preprocess_data(False,\"data.csv\")\n",
    "decompose_data(df,chars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
